{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 背后机制(Under the hood)\n",
    "从线性SVM分类器开始，解释SVM是如何做预测的并且算法是如何工作的。\n",
    "\n",
    "在训练模型章节中，将所有模型参数放在一个矢量$\\vec \\theta$中，包括偏置项$\\theta_0$，$\\theta_1$到$\\theta_n$的输入特征权重，和增加一个偏差输入$x_0=1$到所有样本中。\n",
    "\n",
    "在这里将使用不同的符号约定：偏置项被命名为$b$，特征权重向量被称为$\\vec w$，在输入特征向量中不再添加偏置特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 决策函数和预测\n",
    "线性SVM分类器通过计算函数$w\\cdot x+b=w_1x_1+w_2x_2+...+w_nx_n+b$来预测新样本的类别：\n",
    "* 如果结果是正的，预测类别$\\hat{y}$是正类，为1\n",
    "* 如果结果是负的，预测类别$\\hat{y}$是负类，为0\n",
    "\n",
    "公式为：\n",
    "$\\hat{y}=\\begin{cases} 0, if w^T\\cdot x+b<0\\\\ 1,ifw^T\\cdot x+b\\geq0 \\end{cases}$\n",
    "\n",
    "训练线性SVM分类器意味着找到$w$值和$b$值使得这一个间隔尽可能大，同时避免间隔违规（硬间隔）或限制它们（软间隔）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.训练目标\n",
    "决策函数的斜率：它等于权重向量的范数$\\parallel w\\parallel$。\n",
    "\n",
    "权重向量$w$越小，间隔越大。所以我们的目标是最小化$\\parallel w\\parallel$，从而获得大的间隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x320 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_2D_decision_function(w, b, ylabel=True, x1_lim=[-3, 3]):\n",
    "    x1 = np.linspace(x1_lim[0], x1_lim[1], 200)\n",
    "    y = w * x1 + b\n",
    "    m = 1 / w\n",
    "\n",
    "    plt.plot(x1, y)\n",
    "    \n",
    "    plt.plot(x1_lim, [1, 1], \"k:\")  # 画y=1的虚线\n",
    "    plt.plot(x1_lim, [-1, -1], \"k:\")  # 画y=-1的虚线\n",
    "    \n",
    "    plt.axhline(y=0, color='k')  # 画X坐标轴\n",
    "    plt.axvline(x=0, color='k')  # 画Y坐标轴\n",
    "    \n",
    "    plt.plot([m, m], [0, 1], \"k--\")  # 画纵向虚线\n",
    "    plt.plot([-m, -m], [0, -1], \"k--\")\n",
    "    \n",
    "    plt.plot([-m, m], [0, 0], \"k-o\", linewidth=3)  # 画[-m,m]直线，注意'k-o'表示法，不仅画出直线还标志出两头的起止点\n",
    "    \n",
    "    plt.axis(x1_lim + [-2, 2])\n",
    "    \n",
    "    plt.xlabel(r\"$x_1$\", fontsize=16)\n",
    "    if ylabel:\n",
    "        plt.ylabel(r\"$w_1 x_1$  \", rotation=0, fontsize=16)\n",
    "    plt.title(r\"$w_1 = {}$\".format(w), fontsize=16)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(12, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_2D_decision_function(1, 0)\n",
    "plt.subplot(122)\n",
    "plot_2D_decision_function(0.5, 0, ylabel=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以看到，将斜率除以2，决策函数等于$\\pm1$的点将会离决策边界原来的两倍远"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1避免间隔违规(硬间隔)\n",
    "* 对于正的训练样本，需要决策函数大于1\n",
    "* 对于负的训练样本，小于-1\n",
    "\n",
    "对负样本(即$y^{(i)}=0$)定义$t^{(i)}=-1$；对正样本(即$y^{(i)}=1$)定义$t^{(i)}=1$。则可以将所有的样本表示为$t^{(i)}(w^Tx^{(i)}+b)\\geq1$\n",
    "\n",
    "硬间隔线性SVM分类器表示为下列约束优化问题：\n",
    "\n",
    "$minimize_{w,b}\\quad \\frac{1}{2}w^T\\cdot w$\n",
    "\n",
    "$subject\\ to \\quad t^{(i)}(w^T\\cdot x^{(i)}+b)\\geq 1\\quad for\\ i=1,2,\\dots,m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 获得软间隔的目标\n",
    "应用松弛变量(slack variable)$\\zeta^{(i)}\\geq0$，表示第$i$个样本允许违规间隔的程度\n",
    "现在有两个不一致的目标：\n",
    "* 一个是使松弛变量尽可能的小，从而减小间隔违规\n",
    "* 另一个是使$\\frac{1}{2}w\\cdot w$尽量小，从而增大间隔\n",
    "\n",
    "超参数$C$发挥作用：它允许我们在两个目标之间权衡\n",
    "\n",
    "约束优化问题为：\n",
    "\n",
    "$minimize_{w,b,\\zeta}\\quad \\frac{1}{2}w^T\\cdot w+C\\sum_{i=1}^{m}\\zeta$\n",
    "\n",
    "$subject\\ to \\quad t^{(i)}(w^T\\cdot x^{(i)}+b)\\geq 1-\\zeta^{(i)}\\quad and\\quad \\zeta^{(i)}\\quad for\\ i=1,2,\\dots,m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.二次规划\n",
    "硬间隔和软间隔都是线性约束的凸二次规划优化问题。这些问题被称之为二次规划（QP）问题。\n",
    "\n",
    "一般问题的公式为：\n",
    "\n",
    "$minisize\\quad \\frac{1}{2}p^T\\cdot H\\cdot p+f^T\\cdot p$\n",
    "\n",
    "$subject\\ to\\quad A\\cdot p\\leq b$\n",
    "\n",
    "$where\\\n",
    "\\begin{cases}\n",
    "\\vec p\\ is\\ an\\ n_p-dimensional\\ vector(n_p=number\\ of\\ paramters)\\\\\n",
    "\\vec H\\ is\\ an\\ n_p\\times n_p\\ matrix\\\\\n",
    "\\vec f\\ is\\ an\\ n_p-dimensional\\ vector\\\\\n",
    "\\vec A\\ is\\ an\\ n_c\\times n_p\\ matrix(n_c=number\\ of\\ contraints)\\\\\n",
    "\\vec b\\ is\\ an\\ n_c-dimensional\\ vector \n",
    "\\end{cases}$\n",
    "\n",
    "可以很容易看到，如果用以下的方式设置QP的参数，将获得硬间隔线性SVM分类器的目标：\n",
    "* $n_p=n+1,\\ n $表示特征的数量（+1是偏置项）\n",
    "* $n_c=m,\\ m$表示训练样本数量\n",
    "* $\\vec H$是$n_c\\times n_p$单位矩阵，除了左上角为0（忽略偏置项）\n",
    "* $\\vec f=0$，一个全为0的$n_p$维向量\n",
    "* $b=1$，一个全为1的$n_c$维向量\n",
    "* $a^{(i)}=t^{(i)}x^{(i)},\\ x^{(i)}$等于$x^{(i)}$带一个额外的偏执特征$x_0=1$\n",
    "\n",
    "所以训练硬间隔线性SVM分类器的一种方式是使用现有的QP解决方案，即上述的参数\n",
    "\n",
    "然而使用核技巧我们将会看到一个不同的约束优化问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 对偶问题\n",
    "给定一个约束优化问题，即原始问题（primal problem），它可能表示不同但是和另一个问题紧密相连，称为对偶问题（dual problem）。\n",
    "\n",
    "对偶问题的解通常对原始问题的解给出一个下界约束，在某些条件下可以获得相同的解。\n",
    "\n",
    "幸运的是，SVM问题恰好满足这些条件，所以可以选择解决原始问题或者对偶问题，两者将会有相同解。\n",
    "\n",
    "线性SVM的对偶形式表示为：\n",
    "\n",
    "$$minisize_{\\alpha} \\quad \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha^{(i)}\\alpha^{(j)}t^{(i)}t^{(j)}x^{(i)T}\\cdot x^{(j)}\\ -\\ \\sum_{i=1}^{m}\\alpha^{(i)}$$\n",
    "\n",
    "$$subject\\ to\\quad \\alpha^{(i)}\\geq 0\\quad for\\ i=1,2,\\dots ,m$$\n",
    "\n",
    "一旦找到最小化公式的向量$\\vec \\alpha$（使用QP解决方案），可以使用下面的方式计算$w$和$b$，从而使原始问题最小化。\n",
    "\n",
    "$$w=\\sum_{i=1}^{m}\\hat{a}^{(i)}t^{(i)}x^{(i)}$$\n",
    "\n",
    "$$\\hat{b}=\\frac{1}{n_s}\\sum_{i=1\\\\ \\hat{a}^{(i)}>0}(1-t^{(i)}(w^T\\cdot x^{(i)}))$$\n",
    "\n",
    "解决了线性SVM分类器从对偶解到原始解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 核化支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设把一个二次多项式应用到二维空间的训练集，然后在变换后的训练集上训练一个线性SVM分类器.\n",
    "二次多项式映射函数为：\n",
    "\n",
    "$\\phi(x)=\\phi(\\begin{pmatrix}x_1\\\\x_2\\\\ \\end{pmatrix})=\\begin{pmatrix}x_1^2\\\\\\sqrt{2}x_1x_2\\\\x_2^2\\\\ \\end{pmatrix}$\n",
    "\n",
    "如果我们应用这个二次多项式映射，然后计算转换后向量的点积，则：\n",
    "\n",
    "$\\phi(a)^T\\cdot \\phi(b)=\\begin{pmatrix}a_1^2\\\\\\sqrt{2}a_1a_2\\\\b_2^2\\\\ \\end{pmatrix}\\cdot \\begin{pmatrix}b_1^2\\\\\\sqrt{2}b_1b_2\\\\b_2^2\\\\ \\end{pmatrix}=a_1^2b_1^2+2a_1b_1a_2b_2+a_2^2b_2^2=(a_1b_1+a_2b_2)^2=(\\begin{pmatrix}a_1\\\\a_2 \\end{pmatrix}^T\\cdot \\begin{pmatrix}b_1\\\\b_2 \\end{pmatrix})=(a^T\\cdot b)^2$\n",
    "\n",
    "**转换后向量的点积等于原始向量点积的平方**：$\\phi(a)^T\\cdot \\phi(b)=(a^Tb)^T$\n",
    "\n",
    "所以实际上不需要对训练集进行转换：仅仅需要在SVM的对偶形式中，将点积替换成它点积的平方。结果将会个经过麻烦的训练集转换并拟合出线性SVM算法得出的结果一结果一样，但是这个技巧使得整个过程在计算上面更有效率。**这就是核技巧的精髓**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数$K(a,b)=(a^Tb)^2$被称为二次多项式核(polynomial kernel)。在机器学习中，核函数是一个能计算点积的函数，并只基于原始向量$a$和$b$，不需要计算（甚至知道）转换$\\phi$。一下列举了一些常用的核函数：\n",
    "$$\\ Linear:\\quad K(a,b)=a^Tb$$\n",
    "$$\\quad \\quad Polynomial:\\quad K(a,b)=(\\gamma a^T\\cdot b+r)^d$$\n",
    "$$\\quad \\quad Gaussian RBF:\\quad K(a,b)=exp(-\\gamma \\parallel a-b\\parallel^2$$\n",
    "$$\\quad \\quad Sgimoid:\\quad K(a,b)=tanh(\\gamma a^T\\cdot +r)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将$w$代入到新的样本$x^{(n)}$的决策函数中，会得到一个在输入向量之间只有点积的方程式，这时，核技巧将派上用场。\n",
    "\n",
    "$$h_{w,\\hat{b}}(\\phi(x^{(n)}))=w^T\\cdot\\phi(x^{(n)})+\\hat{b}=(\\sum_{i=1}^{m}\\hat{a}^{(i)}t^{(i)}\\phi(x^{(i)}))^T\\cdot \\phi(x^{(n)})+\\hat{b}\\\\\n",
    "=\\sum_{i=1}^{m}\\hat{a}^{(i)}t^{(i)}(\\phi(x^{(i)})^T\\cot \\phi(x^{(n)})+\\hat{b}\\\\\n",
    "=\\sum_{i=1\\\\\\hat{a}^{(i)}>0}^{m}\\hat{a}^{(i)}t^{(i)}K(x^{i},x^{(n)})+\\hat{b}$$\n",
    "\n",
    "注意到支持向量才满足$a(i)\\neq 0$，做出预测只涉及计算为支持向量部分的输入样本$x^{(n)}的点积，而不是全部的训练样本。\n",
    "\n",
    "同样可以使用相同的核技巧来计算偏置项$b$：\n",
    "\n",
    "$$\\hat{b}=\\frac{1}{n_s}\\sum_{i=1\\\\ \\hat{a}^{(i)}>0}^{m}(1-t^{(i)}w^T\\cdot \\phi(x^{(i)}))=\\frac{1}{n_s}\\sum_{i=1\\\\ \\hat{a}^{(i)}>0}^{m}(1-t^{(i)}(\\sum_{j=1}^{m}\\hat{a}^{(j)}t^{(j)}\\phi(x^{(j)}))\\cdot \\phi(x^{(j)}))\\\\\n",
    "=\\frac{1}{n_s}\\sum_{i=1\\\\ \\hat{a}^{(i)}>0}^{m}(1-t^{(i)}\\sum_{j=1\\\\ \\hat{a}^{(j)}>0}\\hat{a}^{(j)}t^{(j)}K(x^{(i)},x^{(j)}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在线支持向量机\n",
    "\n",
    "在线学习意味着增量地学习，不断有新实例\n",
    "\n",
    "对于线性SVM分类器，一种方式是使用梯度下降（如使用SGDClassifier）最小化代价函数：\n",
    "\n",
    "$$J(w,b)=\\frac{1}{2}w^T\\cdot w+C\\sum_{i=1}^{m}\\max (0,1=t^{(i)}(w^T\\cdot x^{(i)}+b))$$\n",
    "\n",
    "* 代价函数第一个和会使模型有一个小的权重向量$w$，从而获得一个更大地间隔\n",
    "* 第二个和计算所有间隔违规地总数\n",
    "\n",
    "如果样本位于\"街道\"上和正确地一遍，或它与\"街道\"正确一边地距离成比例，则间隔违规等于0.最小化保证了模型的间隔违规尽可能小并且少。\n",
    "\n",
    "我们也可以使用现在核化SVM。例如使用\"增量和递减SVM学习\"或者\"在线和主动的快速核分类器\"。但是，这些都是用Matlab和C++实现的。对于大规模飞线性问题，需要考虑使用神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hinge损失\n",
    "\n",
    "函数$\\max(0,1-t)$称为Hinge损失。\n",
    "* 当$t\\geq 1$时，Hinge值为0\n",
    "* 当$t<1$，它的导数(斜率)为-1\n",
    "* 当$t>1$，则等于0\n",
    "* 在$t=1$处，它是不可微的，但是仍然可以在$t=0$处使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x201.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(-2, 4, 200)\n",
    "h = np.where(1 - t < 0, 0, 1 - t)  # max(0, 1-t),np.where(condition, x, y)满足条件输出x,不满足输出y\n",
    "\n",
    "plt.figure(figsize=(5,2.8))\n",
    "plt.plot(t, h, \"b-\", linewidth=2, label=\"$max(0, 1 - t)$\")\n",
    "plt.grid(True, which='both')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.yticks(np.arange(-1, 2.5, 1))\n",
    "plt.xlabel(\"$t$\", fontsize=16)\n",
    "plt.axis([-2, 4, -1, 2.5])\n",
    "plt.legend(loc=\"upper right\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
